_id,args,kwargs,result,time,success
68c36f1f57f58d47e33bb062,[],"{'neuron_selection_mode': 'acc', 'acc_th': 0.02744067519636624, 'num_to_compromise': 5, 'min_separation': 0.99, 'guard_bias_k': 1.7869184264341351, 'backdoor_class': 6, 'target_amplification_factor': 27.50776403889842, 'max_separation_boosting_rounds': 10, 'n_filters_to_compromise': 4, 'conv_filter_boost_factor': 0.44983473861168194}","{'train_stats': {'train_eval_loss': 0.0008940843168387289, 'train_eval_acc': 0.9999330611152019}, 'test_stats': {'test_eval_loss': 0.07293404215044039, 'test_eval_acc': 0.9781186094069529}, 'test_bd_stats': {'test_bd_loss': 14.311115966594048, 'test_bd_acc': 0.07770961145194274}, 'test_bd_neg_stats': {'test_bd_neg_loss': 0.07349716684264883, 'test_bd_neg_acc': 0.9760736196319019}, 'weights/handcrafted_GTSB.pth': 'weights/handcrafted_GTSB.pth', 'args': {'task': ['handcrafted'], 'prefix': 'handcrafted_GTSB', 'dataset': 'GTSB', 'trigger': ""checkerboard('bottomleft', (3, 3), colours=(255, 0))"", 'backdoor_class': 6, 'trials': 10, 'seed': 0, 'handcrafted_clean_weights': '/home/wyl/backdoor/experiments/weights/clean_GTSB.pth', 'mongo_url': 'mongodb://localhost:27017/', 'weights_path': 'weights', 'epochs': 50, 'learning_rate': 0.1, 'device': 'cuda', 'no_batchnorm': False, 'use_wandb': False, 'no_annealing': False, 'no_dataaug': False}}",34.00450134277344,True
68c36f2f57f58d47e33bb063,[],"{'neuron_selection_mode': 'acc', 'acc_th': 0.04885365532654934, 'num_to_compromise': 3, 'min_separation': 0.999, 'guard_bias_k': 1.9146941443600896, 'backdoor_class': 6, 'target_amplification_factor': 13.528575807200239, 'max_separation_boosting_rounds': 10, 'n_filters_to_compromise': 1, 'conv_filter_boost_factor': 0.40407500981539624}","BackdoorFailure('Conv2D optimization failed, loss was 0.00860')",16.477047443389893,False
68c36f4a57f58d47e33bb064,[],"{'neuron_selection_mode': 'acc', 'acc_th': 0.04949468252639908, 'num_to_compromise': 1, 'min_separation': 0.9, 'guard_bias_k': 1.2056617821956648, 'backdoor_class': 6, 'target_amplification_factor': 9.326811264135596, 'max_separation_boosting_rounds': 10, 'n_filters_to_compromise': 2, 'conv_filter_boost_factor': 2.945724307558912}","{'train_stats': {'train_eval_loss': 0.11790317029559076, 'train_eval_acc': 0.9700783184952139}, 'test_stats': {'test_eval_loss': 0.25893114743361934, 'test_eval_acc': 0.9259713701431492}, 'test_bd_stats': {'test_bd_loss': 4.592788490537242, 'test_bd_acc': 0.07157464212678936}, 'test_bd_neg_stats': {'test_bd_neg_loss': 1.5730492591004674, 'test_bd_neg_acc': 0.6096114519427402}, 'weights/handcrafted_GTSB.pth': 'weights/handcrafted_GTSB.pth', 'args': {'task': ['handcrafted'], 'prefix': 'handcrafted_GTSB', 'dataset': 'GTSB', 'trigger': ""checkerboard('bottomleft', (3, 3), colours=(255, 0))"", 'backdoor_class': 6, 'trials': 10, 'seed': 0, 'handcrafted_clean_weights': '/home/wyl/backdoor/experiments/weights/clean_GTSB.pth', 'mongo_url': 'mongodb://localhost:27017/', 'weights_path': 'weights', 'epochs': 50, 'learning_rate': 0.1, 'device': 'cuda', 'no_batchnorm': False, 'use_wandb': False, 'no_annealing': False, 'no_dataaug': False}}",27.234905004501343,True
68c36f6a57f58d47e33bb065,[],"{'neuron_selection_mode': 'acc', 'acc_th': 0.013816226592567971, 'num_to_compromise': 3, 'min_separation': 0.99, 'guard_bias_k': 0.9984802735367171, 'backdoor_class': 6, 'target_amplification_factor': 1.3592412245544803, 'max_separation_boosting_rounds': 10, 'n_filters_to_compromise': 2, 'conv_filter_boost_factor': 0.8039284046985821}","{'train_stats': {'train_eval_loss': 5.143787561313298e-05, 'train_eval_acc': 1.0}, 'test_stats': {'test_eval_loss': 0.07912403726321787, 'test_eval_acc': 0.9797546012269939}, 'test_bd_stats': {'test_bd_loss': 15.275657616363713, 'test_bd_acc': 0.07832310838445808}, 'test_bd_neg_stats': {'test_bd_neg_loss': 0.07908740436738254, 'test_bd_neg_acc': 0.9789366053169735}, 'weights/handcrafted_GTSB.pth': 'weights/handcrafted_GTSB.pth', 'args': {'task': ['handcrafted'], 'prefix': 'handcrafted_GTSB', 'dataset': 'GTSB', 'trigger': ""checkerboard('bottomleft', (3, 3), colours=(255, 0))"", 'backdoor_class': 6, 'trials': 10, 'seed': 0, 'handcrafted_clean_weights': '/home/wyl/backdoor/experiments/weights/clean_GTSB.pth', 'mongo_url': 'mongodb://localhost:27017/', 'weights_path': 'weights', 'epochs': 50, 'learning_rate': 0.1, 'device': 'cuda', 'no_batchnorm': False, 'use_wandb': False, 'no_annealing': False, 'no_dataaug': False}}",31.565279006958008,True
68c36f7757f58d47e33bb066,[],"{'neuron_selection_mode': 'acc', 'acc_th': 0.037307399403194795, 'num_to_compromise': 6, 'min_separation': 0.98, 'guard_bias_k': 0.8959028425013134, 'backdoor_class': 6, 'target_amplification_factor': 34.177916391545374, 'max_separation_boosting_rounds': 10, 'n_filters_to_compromise': 1, 'conv_filter_boost_factor': 1.5800980302415235}","BackdoorFailure('Conv2D optimization failed, loss was 0.00539')",12.991186618804932,False
68c36f9857f58d47e33bb067,[],"{'neuron_selection_mode': 'acc', 'acc_th': 0.012005228747353254, 'num_to_compromise': 2, 'min_separation': 0.95, 'guard_bias_k': 1.1163627408987993, 'backdoor_class': 6, 'target_amplification_factor': 3.9416416615174152, 'max_separation_boosting_rounds': 10, 'n_filters_to_compromise': 4, 'conv_filter_boost_factor': 3.0655838950102563}","{'train_stats': {'train_eval_loss': 0.7302293151674903, 'train_eval_acc': 0.8540732311399692}, 'test_stats': {'test_eval_loss': 1.0708400100042972, 'test_eval_acc': 0.7807770961145194}, 'test_bd_stats': {'test_bd_loss': 51.60542187524963, 'test_bd_acc': 0.0}, 'test_bd_neg_stats': {'test_bd_neg_loss': 76.11514568055821, 'test_bd_neg_acc': 0.1411042944785276}, 'weights/handcrafted_GTSB.pth': 'weights/handcrafted_GTSB.pth', 'args': {'task': ['handcrafted'], 'prefix': 'handcrafted_GTSB', 'dataset': 'GTSB', 'trigger': ""checkerboard('bottomleft', (3, 3), colours=(255, 0))"", 'backdoor_class': 6, 'trials': 10, 'seed': 0, 'handcrafted_clean_weights': '/home/wyl/backdoor/experiments/weights/clean_GTSB.pth', 'mongo_url': 'mongodb://localhost:27017/', 'weights_path': 'weights', 'epochs': 50, 'learning_rate': 0.1, 'device': 'cuda', 'no_batchnorm': False, 'use_wandb': False, 'no_annealing': False, 'no_dataaug': False}}",32.72446823120117,True
68c36fba57f58d47e33bb068,[],"{'neuron_selection_mode': 'acc', 'acc_th': 0.04730758583478452, 'num_to_compromise': 1, 'min_separation': 0.995, 'guard_bias_k': 1.7280513334143501, 'backdoor_class': 6, 'target_amplification_factor': 5.345056969128347, 'max_separation_boosting_rounds': 10, 'n_filters_to_compromise': 7, 'conv_filter_boost_factor': 1.3570332707336192}","{'train_stats': {'train_eval_loss': 0.08232485997527429, 'train_eval_acc': 0.9758350625878572}, 'test_stats': {'test_eval_loss': 0.32019251110851155, 'test_eval_acc': 0.9059304703476483}, 'test_bd_stats': {'test_bd_loss': 1.2537521544409675, 'test_bd_acc': 0.5139059304703476}, 'test_bd_neg_stats': {'test_bd_neg_loss': 6.322919286833219, 'test_bd_neg_acc': 0.2116564417177914}, 'weights/handcrafted_GTSB.pth': 'weights/handcrafted_GTSB.pth', 'args': {'task': ['handcrafted'], 'prefix': 'handcrafted_GTSB', 'dataset': 'GTSB', 'trigger': ""checkerboard('bottomleft', (3, 3), colours=(255, 0))"", 'backdoor_class': 6, 'trials': 10, 'seed': 0, 'handcrafted_clean_weights': '/home/wyl/backdoor/experiments/weights/clean_GTSB.pth', 'mongo_url': 'mongodb://localhost:27017/', 'weights_path': 'weights', 'epochs': 50, 'learning_rate': 0.1, 'device': 'cuda', 'no_batchnorm': False, 'use_wandb': False, 'no_annealing': False, 'no_dataaug': False}}",34.43829894065857,True
68c36fdb57f58d47e33bb069,[],"{'neuron_selection_mode': 'acc', 'acc_th': 0.010966471129202056, 'num_to_compromise': 5, 'min_separation': 0.995, 'guard_bias_k': 1.1022295941594582, 'backdoor_class': 6, 'target_amplification_factor': 36.535666224363965, 'max_separation_boosting_rounds': 10, 'n_filters_to_compromise': 3, 'conv_filter_boost_factor': 1.058938090547852}","OutOfMemoryError('CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 21.12 MiB is free. Process 4049996 has 548.00 MiB memory in use. Including non-PyTorch memory, this process has 23.07 GiB memory in use. Of the allocated memory 22.49 GiB is allocated by PyTorch, and 123.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)')",32.900887966156006,False
68c36fdb57f58d47e33bb06a,[],"{'neuron_selection_mode': 'acc', 'acc_th': 0.01027169927571754, 'num_to_compromise': 4, 'min_separation': 0.98, 'guard_bias_k': 1.4279597888109041, 'backdoor_class': 6, 'target_amplification_factor': 4.612067650773175, 'max_separation_boosting_rounds': 10, 'n_filters_to_compromise': 3, 'conv_filter_boost_factor': 0.4290412544796229}","OutOfMemoryError('CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 21.12 MiB is free. Process 4049996 has 548.00 MiB memory in use. Including non-PyTorch memory, this process has 23.07 GiB memory in use. Of the allocated memory 22.54 GiB is allocated by PyTorch, and 79.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)')",0.05234980583190918,False
68c36fdb57f58d47e33bb06b,[],"{'neuron_selection_mode': 'acc', 'acc_th': 0.048758092139053785, 'num_to_compromise': 5, 'min_separation': 0.95, 'guard_bias_k': 1.6026095123932493, 'backdoor_class': 6, 'target_amplification_factor': 2.032422073736336, 'max_separation_boosting_rounds': 10, 'n_filters_to_compromise': 1, 'conv_filter_boost_factor': 0.5866997220999232}","OutOfMemoryError('CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 1.12 MiB is free. Process 4049996 has 548.00 MiB memory in use. Including non-PyTorch memory, this process has 23.09 GiB memory in use. Of the allocated memory 22.57 GiB is allocated by PyTorch, and 63.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)')",0.04346013069152832,False
